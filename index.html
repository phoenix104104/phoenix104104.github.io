<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <meta name="author" content="jasonlai">
  <title>Wei-Sheng Lai's Homepage</title>

  <!-- CSS  -->
  <link href="css/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/aos.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/font-awesome.min.css" rel="stylesheet" >
  <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection"/>

  <link rel="shortcut icon" href="images/bird.jpg">
</head>
<body>
  
  <div class="navbar-fixed">

    <nav class="">
      <div class="nav-wrapper container"><a id="logo-container" href="#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light" href="#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#about">About</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#publication">Publications</a></li>
        </ul>

      </div>
    </nav>
  </div>

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="images/profile.jpg">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name">Wei-Sheng (Jason) Lai</h5>

        <hr>

        <h6 class="profile-link">Senior Software Engineer</h6 class="profile-link">
        <h6 class="profile-link">Google</h6 class="profile-link">

        <h1></h1>

        <a href="CV.pdf" target="blank"><img class="responsive-img social-photo " src="images/icons/cv.png"></a>

        <a href="https://scholar.google.com/citations?user=miE8bYkAAAAJ&hl=en" target="blank"><img class="responsive-img social-photo " src="images/icons/google_scholar.png"></a>

        <a href="https://github.com/phoenix104104" target="blank"><img class="responsive-img social-photo " src="images/icons/github.png"></a>

        <a href="https://www.linkedin.com/in/weishenglai" target="blank"><img class="responsive-img social-photo" src="images/icons/linkedin.png"></a>

    </div>
    
  </div>

  <div class="parallax"><img src="images/cover_blur.jpg" alt="Unsplashed background img 1"></div>
  
</div>


<!--==========================================
                   About
===========================================-->
<div class="section about-section scrollspy" id="about">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title">About Me</div>
      <hr>
    </div>
    
    <div class="row">
      <p>
        I am a senior software engineer at Google, working on mobile computational photography.
        I received my Ph.D. from the EECS department at <a href="http://www.ucmerced.edu/" target="blank">University of California, Merced</a></h6 class="profile-link"> in 2019, under the advisement of Prof. <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>. 
        Before coming to UC Merced in 2015, I obtained my B.S. and M.S. degrees from the EE department at <a href="https://www.ntu.edu.tw/english/" target="blank">National Taiwan University</a></h6 class="profile-link"> in 2012 and 2014, respectively.
      <p>
        My research interests include <b>Computer Vision</b>, <b>Computational Photography</b> and <b>Machine Learning</b>.
        I am lucky to have opportunities to work with 
        <a href="https://filebox.ece.vt.edu/~jbhuang/index.html" target="blank">Jia-Bin Huang</a> (Virginia Tech), 
        <a href="http://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a> (Google), 
        <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a> (Google), 
        <a href="http://research.nvidia.com/person/deqing-sun" target="blank">Deqing Sun</a> (Nvidia Research), 
        <a href="http://www.gujinwei.org/" target="blank">Jinwei Gu</a> (Nvidia Research), 
        <a href="http://alumni.soe.ucsc.edu/~orazio/" target="blank">Orazio Gallo</a> (Nvidia Research), 
        <a href="http://jankautz.com/" target="blank">Jan Kautz</a> (Nvidia Research), 
        <a href="http://www.meyumer.com/" target="blank">Ersin Yumer</a> (Adobe Research), 
        <a href="http://www.oliverwang.info/" target="blank">Oliver Wang</a> (Adobe Research), 
        <a href="https://research.adobe.com/person/eli-shechtman/" target="blank">Eli Shechtman</a> (Adobe Research), 
        <a href="http://neelj.com/" target="blank">Neel Joshi</a> (Microsoft Research), 
        <a href="https://www.microsoft.com/en-us/research/people/sbkang/" target="blank">Sing Bing Kang</a> (Microsoft Research), 
        <a href="http://www.citi.sinica.edu.tw/pages/yylin/index_zh.html" target="blank">Yen-Yu Lin</a> (Academia Sinica), 
        and 
        <a href="http://www.csie.ntu.edu.tw/~cyy" target="blank">Yung-Yu Chuang</a> (National Taiwan University).
      </p>

      <p>
        I have collaborated with the following interns so far:
        <a href="https://cseweb.ucsd.edu/~k2lin/" target="blank">Kai-En Lin</a> (2021), 
        <a href="https://xidexia.github.io/" target="blank">Xide Xia</a> (2020), 
        <a href="http://pages.cs.wisc.edu/~zhmeishi/" target="blank">Zhenmei Shi</a> (2020), 
        <a href="http://chengao.vision/" target="blank">Chen Gao</a> (2020).
      </p>

    </div>

    <div class="row">

      <ul class="timeline">

          <li data-aos="fade-right" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <img class="responsive-img about-photo" src="images/about/google.jpg">
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://www.nvidia.com/en-us/research/" target="blank">
                      Google
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Senior Software Engineer, Nov. 2021 - Present</p>
                    <p>Software Engineer, Aug. 2019 - Oct. 2021</p>
                  </div>
                </div>
              </div>
          </li>

          <li class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4 timeline-logo-inverted">
                  <a href="https://ai.google/research/teams/cloud-ai/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/google_cloud.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://research.adobe.com/" target="blank">
                      Google Cloud AI
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Student Researcher</p>
                    <p>Dec. 2018 - May 2019</p>
                  </div>
                </div>
                
              </div>
          </li>

          <li data-aos="fade-right" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="https://www.nvidia.com/en-us/research/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/nvidia.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://www.nvidia.com/en-us/research/" target="blank">
                      Nvidia Research
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Research intern</p>
                    <p>May 2018 - Nov. 2018</p>
                    <p>Sep. 2017 - Nov. 2017</p>
                  </div>
                </div>
              </div>
          </li>
          
          <li class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4 timeline-logo-inverted">
                  <a href="https://research.adobe.com/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/adobe.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://research.adobe.com/" target="blank">
                      Adobe Research
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Research intern</p>
                    <p>May 2017 - Aug. 2017</p>
                  </div>
                </div>
                
              </div>
          </li>
          
          <li data-aos="fade-right" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="https://www.microsoft.com/en-us/research/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/MSR.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://www.microsoft.com/en-us/research/" target="blank">
                      Microsoft Research
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Research intern</p>
                    <p>May 2016 - Aug. 2016</p>
                  </div>
                </div>
              </div>
          </li>
          
          <li class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="http://www.ucmerced.edu/" target="blank">
                    <img class="responsive-img about-photo" src="images/about/ucmerced.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="http://www.ucmerced.edu/" target="blank">
                      University of California, Merced
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Ph.D.</p>
                    <p>Aug. 2015 - Jul. 2019</p>
                  </div>
                </div>
                
              </div>

          </li>
          
          <li data-aos="fade-right" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="https://www.sinica.edu.tw/en" target="blank">
                    <img class="responsive-img about-photo" src="images/about/sinica.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="https://www.sinica.edu.tw/en" target="blank">
                      Academia Sinica
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>Research assistant</p>
                    <p>Aug. 2014 - Jul. 2015</p>
                  </div>
                </div>
              </div>
          </li>
          
          <li  class="timeline-inverted" data-aos="fade-left" data-aos-offset="300" data-aos-easing="ease-in-sine" data-aos-duration="500">
              <div class="timeline-badge">
                <i class="fa fa-plus-circle invert" id=""></i>
              </div>
              <div class="timeline-panel">
                <div class="col s4">
                  <a href="http://www.ntu.edu.tw/english/index.html" target="blank">
                    <img class="responsive-img about-photo" src="images/about/NTU.jpg">
                  </a>
                </div>
                <div class="col s8">
                  <div class="timeline-heading">
                    <a href="http://www.ntu.edu.tw/english/index.html" target="blank">
                      National Taiwan University
                    </a>
                  </div>
                  <div class="timeline-body">
                    <p>B.S., M.S.</p>
                    <p>Sep. 2008 - Jul. 2015</p>
                  </div>
                </div>
                
              </div>
          </li>
          <li class="clearfix no-float"></li>
      </ul>

    </div>
  
  
  </div>
</div>


<!--==========================================
                   Publication
===========================================-->
<div class="section publication-section scrollspy" id="publication">

  <div class="row container">
    <div class="row">
      <div class="title">Publications</div>
      <hr>
    </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/fusion_deblur/" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/siggraph22_fusion_deblur.gif">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Face Deblurring using Dual Camera Fusion on Mobile Phones</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            <a href="https://www.linkedin.com/in/lcchu/" target="blank">Lun-Cheng Chu</a>, 
            <a href="https://www.linkedin.com/in/xiaotong-wu-127705a0/" target="blank">Xiaotong Wu</a>, 
            <a href="https://www.linkedin.com/in/sung-fang-tsai-5455b43b/" target="blank">Sung-Fang Tsai</a>, 
            <a href="https://scholar.google.com/citations?hl=en&user=h_Izm-wAAAAJ&view_op=list_works&sortby=pubdate" target="blank">Michael Krainin</a>, 
            <a href="https://deqings.github.io/" target="blank">Deqing Sun</a>, 
            and
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>
            </div>
          <div class="paper-conf">ACM Transactions on Graphics (SIGGRAPH), 2022</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2207.11617" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/fusion_deblur/" target="blank">project website</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://cseweb.ucsd.edu/~viscomp/projects/VisionNeRF/" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/vision_nerf.gif">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Vision Transformer for NeRF-Based View Synthesis from a Single Input Image</div>
          <div class="paper-author">
            <a href="https://cseweb.ucsd.edu/~k2lin/" target="blank">Kai-En Lin</a>, 
            <a href="https://yenchenlin.me/" target="blank">Lin Yen-Chen</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://tsungyilin.info/" target="blank">Tsung-Yi Lin</a>, 
            <a href="http://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            and
            <a href="https://cseweb.ucsd.edu/~ravir/" target="blank">Ravi Ramamoorthi</a>
            </div>
          <div class="paper-conf">arXiv, 2022</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2207.05736" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://cseweb.ucsd.edu/~viscomp/projects/VisionNeRF/" target="blank">project website</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://www.wslai.net/publications/video_face_correction/" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/tip_video_face_correction.gif">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Correcting Face Distortion in Wide-Angle Videos</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>,
            and
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
            </div>
          <div class="paper-conf">IEEE Transactions on Image Processing <b>(TIP)</b>, 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2111.09950" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://www.wslai.net/publications/video_face_correction/" target="blank">project website</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/2105.13016" target="blank">
            <img class="responsive-img" src="images/publications/wacv22_3dstyletransfer.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Stylizing 3D Scene via Implicit Representation and HyperNetwork</div>
          <div class="paper-author"> 
            Pei-Ze Chiang, 
            Meng-Shiun Tsai, 
            <a href="https://hytseng0509.github.io/" target="blank">Hung-Yu Tseng</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            and
            <a href="https://walonchiu.github.io/" target="blank">Wei-Chen Chiu</a>
          </div>
          <div class="paper-conf">IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2022</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2105.13016" target="blank">paper</a>
          </div> 
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://ztex08010518.github.io/3dstyletransfer/" target="blank">project website</a>
          </div>
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/2102.01279" target="blank">
            <img class="responsive-img" src="images/publications/dvs.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Deep Online Fused Video Stabilization</div>
          <div class="paper-author"> 
            <a href="http://pages.cs.wisc.edu/~zhmeishi/" target="blank">Zhenmei Shi</a>, 
            <a href="http://fuhaoshi.com/" target="blank">Fuhao Shi</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>
            and
            <a href="http://pages.cs.wisc.edu/~yliang/" target="blank">Yingyu Liang</a>
          </div>
          <div class="paper-conf">IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2022</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2102.01279" target="blank">paper</a>
          </div> 
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://zhmeishi.github.io/dvs/" target="blank">project website</a>
          </div>
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://alex04072000.github.io/SOLD/" target="blank">
            <img class="responsive-img" src="images/publications/cvpr20_reflection.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Learning to See Through Obstructions with Layered Decomposition</div>
          <div class="paper-author"> 
            <a href="http://www.cmlab.csie.ntu.edu.tw/~yulunliu/" target="blank">Yu-Lun Liu</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>, 
            <a href="https://www.csie.ntu.edu.tw/~cyy/" target="blank">Yung-Yu Chuang</a>, 
            and
            <a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a>
          </div>
          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2020</div>
          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(PAMI)</b> 2021</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            paper
            <a href="https://arxiv.org/abs/2004.01180" target="blank">[CVPR'20]</a>
            <a href="https://arxiv.org/abs/2008.04902" target="blank">[TPAMI'21]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            project website
            <a href="https://alex04072000.github.io/ObstructionRemoval/" target="blank">[CVPR'20]</a>
            <a href="https://alex04072000.github.io/SOLD/" target="blank">[TPAMI'21]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            code
            <a href="https://github.com/alex04072000/ObstructionRemoval" target="blank">[CVPR'20]</a>
            <a href="https://github.com/alex04072000/SOLD" target="blank">[TPAMI'21]</a>
          </div>
        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://cv.snu.ac.kr/sanghyun_son/ADL_TPAMI_accepted.pdf" target="blank">
            <img class="responsive-img paper-img" src="images/publications/pami21_adaptive.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Toward Real-World Super-Resolution via Adaptive Downsampling Models</div>
          <div class="paper-author">
            <a href="https://scholar.google.co.kr/citations?user=nWaSdu0AAAAJ&hl=en" target="blank">Sanghyun Son*</a>, 
            Jaeha Kim*,
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>,
            and
            <a href="https://cv.snu.ac.kr/index.php/~kmlee/" target="blank">Kyoung Mu Lee</a>
          </div>

          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(PAMI)</b> 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://cv.snu.ac.kr/sanghyun_son/ADL_TPAMI_accepted.pdf" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://cv.snu.ac.kr/sanghyun_son/ADL_TPAMI_accepted_supp.pdf" target="blank">supplementary material</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://alex04072000.github.io/FuSta/" target="blank">
            <img class="responsive-img" src="images/publications/iccv21_nervis.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Hybrid Neural Fusion for Full-frame Video Stabilization</div>
          <div class="paper-author"> 
            <a href="http://www.cmlab.csie.ntu.edu.tw/~yulunliu/" target="blank">Yu-Lun Liu*</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>,
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>, 
            <a href="https://www.csie.ntu.edu.tw/~cyy/" target="blank">Yung-Yu Chuang</a>, 
            and
            <a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a>
          </div>

          <div class="paper-conf">IEEE International Conference on Computer Vision <b>(ICCV)</b>, 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2102.06205" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://alex04072000.github.io/FuSta/" target="blank">project website</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/alex04072000/FuSta" target="blank">code</a>
          </div>
        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/2012.05903" target="blank">
            <img class="responsive-img" src="images/publications/arxiv_portraitNerf.gif">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Portrait Neural Radiance Fields from a Single Image</div>
          <div class="paper-author"> 
            <a href="http://chengao.vision/" target="blank">Chen Gao</a>, 
            <a href="https://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>
            and
            <a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a>
          </div>
          <div class="paper-conf">arXiv, 2021</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2012.05903" target="blank">paper</a>
          </div> 
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://portrait-nerf.github.io/" target="blank">project website</a>
          </div>
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="http://people.cs.nctu.edu.tw/~walon/publications/tseng2021wacv.pdf" target="blank">
            <img class="responsive-img" src="images/publications/wacv21_dual.jpg">
          </a>
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Dual-Stream Fusion Network for Spatiotemporal Video Super-Resolution</div>
          <div class="paper-author"> 
            Min-Yuan Tseng, 
            <a href="https://yenchungchen.github.io/" target="blank">Yen-Chung Chen</a>, 
            Yi-Lun Lee, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://sites.google.com/site/yihsuantsai/" target="blank">Yi-Hsuan Tsai</a>
            and
            <a href="https://walonchiu.github.io/" target="blank">Wei-Chen Chiu</a>
          </div>
          <div class="paper-conf">IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021</div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://people.cs.nctu.edu.tw/~walon/publications/tseng2021wacv.pdf" target="blank">paper</a>
          </div> 
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://people.cs.nctu.edu.tw/~walon/publications/tseng2021wacv_supp.pdf" target="blank">Supplementary material</a>
          </div> 
        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/2010.10056" target="blank">
            <img class="responsive-img" src="images/publications/wacv21_vst.png">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Real-time Localized Photorealistic Video Style Transfer</div>
          <div class="paper-author"> 
            <a href="https://xidexia.github.io/" target="blank">Xide Xia</a>, 
            <a href="https://people.csail.mit.edu/tfxue/" target="blank">Tianfan Xue</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Zheng Sun, 
            Abby Chang, 
            <a href="http://people.bu.edu/bkulis/" target="blank">Brian Kulis</a>
            and
            <a href="https://people.csail.mit.edu/jiawen/" target="blank">Jiawen Chen</a>
          </div>

          <div class="paper-conf">IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2010.10056" target="blank">paper</a>
          </div>
          
        </div>
      </div>



      
      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://alex04072000.github.io/SingleHDR/" target="blank">
            <img class="responsive-img" src="images/publications/cvpr20_hdr.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Single-Image HDR Reconstruction by Learning to Reverse the Camera Pipeline</div>
          <div class="paper-author"> 
            <a href="http://www.cmlab.csie.ntu.edu.tw/~yulunliu/" target="blank">Yu-Lun Liu*</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai*</a></b>, 
            <a href="https://www.cmlab.csie.ntu.edu.tw/~nothinglo/" target="blank">Yu-Sheng Chen</a>, 
            Yi-Lung Kao, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>, 
            <a href="https://www.csie.ntu.edu.tw/~cyy/" target="blank">Yung-Yu Chuang</a>, 
            and
            <a href="https://filebox.ece.vt.edu/~jbhuang/" target="blank">Jia-Bin Huang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2004.01179" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://alex04072000.github.io/SingleHDR/" target="blank">project website</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/alex04072000/SingleHDR" target="blank">code</a>
          </div>
          
        </div>
      </div>


      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://ieeexplore.ieee.org/document/" target="blank">
            <img class="responsive-img" src="images/publications/tip20_depth_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Dynamic Scene Deblurring by Depth Guided Model</div>
          <div class="paper-author">
            <a href="https://sites.google.com/view/lerenhanli/homepage" target="blank">Lerenhan Li</a>, 
            <a href="https://sites.google.com/site/jspanhomepage/" target="blank">Jinshan Pan</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Changxin Gao,
            Nong Sang
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Transactions on Image Processing <b>(TIP)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://ieeexplore.ieee.org/document/" target="blank">paper</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="http://aliensunmin.github.io/project/360-VQA/" target="blank">
            <img class="responsive-img" src="images/publications/wacv20_360vqa.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Visual Question Answering on 360&deg; Images</div>
          <div class="paper-author"> 
            <a href="https://shihhanchou.github.io/" target="blank">Shih-Han Chou</a>, 
            <a href="http://www-scf.usc.edu/~weilunc/" target="blank">Wei-Lun Chao</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://aliensunmin.github.io/" target="blank">Min Sun</a>, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">Winter Conference on Applications of Computer Vision <b>(WACV)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2001.03339" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://aliensunmin.github.io/project/360-VQA/" target="blank">project website</a>
          </div>
          
        </div>
      </div>

      
      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://sites.google.com/site/ziyishenmi/cvpr18_face_deblur" target="blank">
            <img class="responsive-img" src="images/publications/cvpr18_face_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Deep Semantic Face Deblurring</div>
          <div class="paper-author">
            <a href="https://sites.google.com/site/ziyishenmi/" target="blank">Ziyi Shen</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Tingfa Xu, 
            <a href="http://jankautz.com/" target="blank">Jan Kautz</a>, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2018</div>
          <div class="paper-conf">International Journal of Computer Vision <b>(IJCV)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1803.03345" target="blank">conference version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/2001.06822" target="blank">journal version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://sites.google.com/site/ziyishenmi/cvpr18_face_deblur" target="blank">project website</a>
          </div>
          
        </div>
      </div>


      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/1807.10806" target="blank">
            <img class="responsive-img" src="images/publications/bmvc18_SR_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Gated Fusion Network for Degraded Image Super Resolution</div>
          <div class="paper-author"> 
            <a href="http://xinyizhang.tech/" target="blank">Xinyi Zhang</a>, 
            Hang Dong, 
            <a href="https://eng.ucmerced.edu/people/zhu" target="blank">Zhe Hu</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Fei Wang, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">British Machine Vision Conference  <b>(BMVC)</b>, 2018 (<font color="red">Oral presentation</font>)</div> 
          <div class="paper-conf">International Journal of Computer Vision <b>(IJCV)</b>, 2020</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1807.10806" target="blank">conference version</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://link.springer.com/article/10.1007/s11263-019-01285-y" target="blank">journal version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://xinyizhang.tech/bmvc2018/" target="blank">project website</a>
          </div>
          
        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="http://vllab.ucmerced.edu/wlai24/video_stitching/" target="blank">
            <img class="responsive-img" src="images/publications/bmvc19_video_stitching.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Video Stitching for Linear Camera Arrays</div>
          <div class="paper-author"> 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://alumni.soe.ucsc.edu/~orazio/" target="blank">Orazio Gallo</a>, 
            <a href="http://www.gujinwei.org/" target="blank">Jinwei Gu</a>, 
            <a href="https://scholar.google.com/citations?hl=en&user=t4rgICIAAAAJ&view_op=list_works&sortby=pubdate" target="blank">Deqing Sun</a>, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
            and
            <a href="http://jankautz.com/" target="blank">Jan Kautz</a>
          </div>

          <div class="paper-conf">British Machine Vision Conference <b>(BMVC)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://arxiv.org/abs/1907.13622" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://vllab.ucmerced.edu/wlai24/video_stitching/" target="blank">project website</a>
          </div>
          
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="http://people.csail.mit.edu/yichangshih/wide_angle_portrait/" target="blank">
            <div class="cf">
              <img class="responsive-img paper-img" src="images/publications/sig19.gif">
            </div>
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Distortion-Free Wide-Angle Portraits on Camera Phones</div>
          <div class="paper-author">
            <a href="http://people.csail.mit.edu/yichangshih/" target="blank">YiChang Shih</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            and
            <a href="http://chiakailiang.org/" target="blank">Chia-Kai Liang</a>
            </div>
          <div class="paper-conf">ACM Transactions on Graphics <b>(SIGGRAPH)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://people.csail.mit.edu/yichangshih/wide_angle_portrait/shih_sig19_lowres.pdf" target="blank">paper</a>
          </div>
          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://people.csail.mit.edu/yichangshih/wide_angle_portrait/" target="blank">project website</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://sites.google.com/view/wenbobao/dain" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr19_DAIN.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Depth-Aware Video Frame Interpolation</div>
          <div class="paper-author">
            <a href="https://sites.google.com/view/wenbobao/home" target="blank">Wenbo Bao</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://sites.google.com/site/chaoma99/" target="blank">Chao Ma</a>, 
            Xiaoyun Zhang, 
            Zhiyong Gao, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1904.00830" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://sites.google.com/view/wenbobao/dain" target="blank">project website</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/baowenbo/DAIN" target="blank">code</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://sites.google.com/view/wenbobao/memc-net" target="blank">
            <img class="responsive-img paper-img" src="images/publications/MEMCNet.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Frame Interpolation and Enhancement</div>
          <div class="paper-author">
            <a href="https://sites.google.com/view/wenbobao/home" target="blank">Wenbo Bao</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Xiaoyun Zhang, 
            Zhiyong Gao, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(PAMI)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1810.08768" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://sites.google.com/view/wenbobao/memc-net" target="blank">project website</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="http://vllab.ucmerced.edu/wlai24/LapSRN/" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr17_LapSRN.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
              <a href="https://sites.google.com/site/jbhuang0604/" target="blank">Jia-Bin Huang</a>, 
              <a href="http://vision.ai.illinois.edu/ahuja.html" target="blank">Narendra Ahuja</a>, and 
              <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2017</div>
          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(PAMI)</b>, 2018</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://vllab.ucmerced.edu/wlai24/LapSRN/papers/cvpr17_LapSRN.pdf" target="blank">conference version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1710.01992" target="blank">journal version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://vllab.ucmerced.edu/wlai24/LapSRN/" target="blank">project website</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/phoenix104104/LapSRN" target="blank">code</a>
          </div>

        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="http://vllab.ucmerced.edu/wlai24/video_consistency/" target="blank">
            <img class="responsive-img" src="images/publications/eccv18_video_consistency.gif">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Learning Blind Video Temporal Consistency</div>
          <div class="paper-author"> 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://filebox.ece.vt.edu/~jbhuang/index.html" target="blank">Jia-Bin Huang</a>, 
            <a href="http://www.oliverwang.info/" target="blank">Oliver Wang</a>, 
            <a href="https://research.adobe.com/person/eli-shechtman/" target="blank">Eli Shechtman</a>, 
            <a href="http://www.meyumer.com/" target="blank">Ersin Yumer</a>, 
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">European Conference on Computer Vision <b>(ECCV)</b>, 2018</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://arxiv.org/abs/1808.00449" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://vllab.ucmerced.edu/wlai24/video_consistency/" target="blank">project website</a>
          </div>
          
        </div>
      </div>

      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/1803.03363/" target="blank">
            <img class="responsive-img" src="images/publications/cvpr18_learn_deblur_prior.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Blind Image Deblurring via Deep Discriminative Priors</div>
          <div class="paper-author">
            <a href="https://sites.google.com/view/lerenhanli/homepage" target="blank">Lerenhan Li</a>, 
            <a href="https://sites.google.com/site/jspanhomepage/" target="blank">Jinshan Pan</a>, 
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            Changxin Gao,
            Nong Sang
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2018</div>
          <div class="paper-conf">International Journal of Computer Vision <b>(IJCV)</b>, 2019</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1803.03363" target="blank">conference version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://link.springer.com/article/10.1007/s11263-018-01146-0" target="blank">journal version</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="https://sites.google.com/view/lerenhanli/homepage/learn_prior_deblur" target="blank">project website</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="http://vllab.ucmerced.edu/wlai24/semiFlowGAN/" target="blank">
            <img class="responsive-img" src="images/publications/nips17_flow.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Semi-Supervised Learning for Optical Flow with Generative Adversarial Networks</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://filebox.ece.vt.edu/~jbhuang/index.html" target="blank">Jia-Bin Huang</a>
            and 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">Neural Information Processing Systems <b>(NIPS)</b>, 2017</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://papers.nips.cc/paper/6639-semi-supervised-learning-for-optical-flow-with-generative-adversarial-networks.pdf" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://vllab.ucmerced.edu/wlai24/semiFlowGAN/" target="blank">project website</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="http://vllab.ucmerced.edu/wlai24/360hyperlapse/" target="blank">
            <img class="responsive-img paper-img" src="images/publications/360hyperlapse.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Semantic-driven Generation of Hyperlapse from 360&deg; Video</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="https://www.linkedin.com/in/erichuang0771/" target="blank">Yujia Huang</a>, 
            <a href="http://neelj.com/" target="blank">Neel Joshi</a>, 
            <a href="https://www.linkedin.com/in/christopher-buehler-3656a29/" target="blank">Chris Buehler</a>, 
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>, 
            and
            <a href="https://www.microsoft.com/en-us/research/people/sbkang/" target="blank">Sing Bing Kang</a>
          </div>

          <div class="paper-conf">IEEE Transactions on Visualization and Computer Graphics <b>(TVCG)</b>, 2017</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://arxiv.org/abs/1703.10798" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://vllab.ucmerced.edu/wlai24/360hyperlapse/" target="blank">project website</a>
          </div>


        </div>
      </div>



      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="https://arxiv.org/abs/1611.06495" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr17_nonblind_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Learning Fully Convolutional Networks for Iterative Non-blind Deconvolution</div>
          <div class="paper-author">
            <a href="https://sites.google.com/site/zhjw1988/" target="blank">Jiawei Zhang</a>,
            <a href="https://sites.google.com/site/jspanhomepage/" target="blank">Jinshan Pan</a>,
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
            <a href="http://www.cs.cityu.edu.hk/~rynson/" target="blank">Rynson Lau</a>,
            <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2017</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="https://arxiv.org/abs/1611.06495" target="blank">paper</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <a href="http://vllab.ucmerced.edu/wlai24/cvpr16_deblur_study/" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr16_deblur_study.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">A Comparative Study for Single Image Blind Deblurring</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
              <a href="https://sites.google.com/site/jbhuang0604/" target="blank">Jia-Bin Huang</a>, 
              <a href="https://eng.ucmerced.edu/people/zhu" target="blank">Zhe Hu</a>, 
              <a href="http://vision.ai.illinois.edu/ahuja.html" target="blank">Narendra Ahuja</a>, and 
              <a href="http://faculty.ucmerced.edu/mhyang/" target="blank">Ming-Hsuan Yang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2016  (<font color="red">Spotlight presentation</font>)</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://vllab.ucmerced.edu/wlai24/cvpr16_deblur_study/paper/cvpr16_deblur_study.pdf" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://vllab.ucmerced.edu/wlai24/cvpr16_deblur_study/" target="blank">project website</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/github.jpg">
            <a href="https://github.com/phoenix104104/cvpr16_deblur_study" target="blank">code</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/youtube.jpg">
            <a href="https://www.youtube.com/watch?v=wPWoH-rwJgk" target="blank">CVPR presentation</a>
          </div>

        </div>
      </div>


      <div class="row paper-block">

        <div class="col s12 m12 l4 center">
          <a href="http://cmlab.csie.ntu.edu.tw/~jasonlai/colorline_deblur/" target="blank">
            <img class="responsive-img paper-img" src="images/publications/cvpr15_colorline_deblur.jpg">
          </a>
        </div>

        <div class="col s12 m12 l8">
          <div class="paper-title">Blur Kernel Estimation Using Normalized Color-Line Priors</div>
          <div class="paper-author">
            <b><a href="https://www.wslai.net" target="blank">Wei-Sheng Lai</a></b>, 
              Jian-Jiun Ding, 
              <a href="http://www.citi.sinica.edu.tw/pages/yylin/index_en.html" target="blank">Yen-Yu Lin</a>, and 
              <a href="http://www.csie.ntu.edu.tw/~cyy/" target="blank">Yung-Yu Chuang</a>
          </div>

          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2015</div>

          <div>
            <img class="responsive-img icon" src="images/icons/pdf.jpg">
            <a href="http://www.csie.ntu.edu.tw/~cyy/publications/papers/Lai2015BKE.pdf" target="blank">paper</a>
          </div>

          <div>
            <img class="responsive-img icon" src="images/icons/website.jpg">
            <a href="http://cmlab.csie.ntu.edu.tw/~jasonlai/colorline_deblur/" target="blank">project website</a>
          </div>

        </div>
      </div>

  </div>

</div>


<!--==========================================
                   Activities
===========================================
<div class="section activities-section scrollspy" id="activities">

  <div class="row container">
    <div class="col s12">
      <div class="title">Academic Activities</div>
      <hr>

        <h5>Presentation</h5>
        <ul>
          <li>&emsp; &bull; CVPR 2016 Spotlight presentation, Poster</li>
          <li>&emsp; &bull; CVPR 2015 Poster</li>
        </ul>

        <h5>Conference Reviewer</h5>
        <ul>
          <li>&emsp; &bull; IEEE Conference on Computer Vision and Pattern Recognition, 2017 (<b>CVPR 2017</b>)</li>
          <li>&emsp; &bull; European Conference on Computer Vision, 2016 (<b>ECCV 2016</b>)</li>
          <li>&emsp; &bull; Asian Conference on Computer Vision, 2016 (<b>ACCV 2016</b>)</li>
          <li>&emsp; &bull; Neural Information Processing Systems, 2016 (<b>NIPS 2016</b>)</li>
          <li>&emsp; &bull; Pacific Graphics, 2016 (<b>PG 2016</b>)</li>
        </ul>

        <h5>Journal Reviewer</h5>
        <ul>
          <li>&emsp; &bull; Computer Vision and Image Understanding (<b>CVIU</b>)</li>
          <li>&emsp; &bull; Signal, Image and Video Processing (<b>SVIP</b>)</li>
        </ul>

    </div>
  </div>

</div>-->

<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer white lighten-4">
    <div class="row">
      <div class="col l4 offset-l4 s12">
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=330&t=tt&d=NjaSaq4L045rBnmichOgvAwPcadRYvfRA0vmRVDeG-k"></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Copyright  Jason Lai 2017
    </div>
  
</footer>


<!--  Scripts-->
<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="js/materialize.js"></script>
<script src="js/aos.js"></script>
<script src="js/init.js"></script>

</body>
</html>
